# ğŸ§  Anamoli AI â€” AI-Powered Observability Platform

**Anamoli AI** is an intelligent observability system that leverages **LLMs (Groq)**, **LangChain**, **RAG (Retrieval-Augmented Generation)**, and **Vector Databases (Chroma)** to analyze logs, detect anomalies, and enable conversational queries about your systems â€” all integrated with **Firestore** and a **React frontend**.

---

## ğŸš€ Project Summary

Modern distributed systems produce millions of logs daily. Finding anomalies and understanding root causes manually is slow and error-prone.

**Anamoli AI** automates observability through:

- ğŸ§© **AI-powered log parsing and anomaly detection**  
- ğŸ” **Semantic search & RAG-based reasoning**  
- ğŸ’¬ **Conversational interface for querying system health**  
- ğŸ“Š **Firestore-based real-time updates**

This allows DevOps and engineers to **chat with their infrastructure** for insights and resolutions in real time.

---

## âš™ï¸ How to Run the Project

### ğŸ§© Backend â€” FastAPI + LangChain + Groq

#### 1ï¸âƒ£ Create Virtual Environment
```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

#### 2ï¸âƒ£ Create `.env` File and Configure service account key for firestore
Inside `backend/`:

```env
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=openai/gpt-oss-20b
GROQ_EMBED_MODEL=nomic-embed-text-v1.5
GOOGLE_APPLICATION_CREDENTIALS=firestore-service-key.json
CHROMA_PATH=./chroma_store
```

Inside `backend/`:
There is a file named by firestore-service-key.json: 
```
You need to add the service account key json details for configuring firestore operations in your backend
```

#### 3ï¸âƒ£ Run the Server
```bash
uvicorn main:app --reload
```

Backend runs on:
ğŸ“ **http://127.0.0.1:8000**

---

### ğŸ’¬ Frontend â€” React + Firestore

#### 1ï¸âƒ£ Install Dependencies
```bash
cd frontend
npm install
npm start
```

Frontend runs on:
ğŸ“ **http://localhost:3000**

#### 2ï¸âƒ£ Configure Firebase
In `/frontend/src/firebaseConfig.js`:

```js
import { initializeApp } from "firebase/app";
import { getFirestore } from "firebase/firestore";

const firebaseConfig = {
  apiKey: "your-api-key",
  authDomain: "your-app.firebaseapp.com",
  projectId: "your-project-id",
  storageBucket: "your-app.appspot.com",
  messagingSenderId: "your-sender-id",
  appId: "your-app-id"
};

const app = initializeApp(firebaseConfig);
export const db = getFirestore(app);
```

---

## ğŸ§  System Architecture Overview

```mermaid
graph TD
  A[User / DevOps Engineer] --> B[React Frontend]
  B --> C[FastAPI Backend]
  C --> D[Groq + LangChain Engine]
  D --> E[Chroma VectorDB]
  C --> F[Firestore Database]
  E --> D
  D --> C
  C --> F
  F --> B
```

### ğŸ§© Components Overview

| Layer                  | Description                                                              |
| ---------------------- | ------------------------------------------------------------------------ |
| **Frontend (React)**   | Interactive chat + real-time updates from Firestore                      |
| **Backend (FastAPI)**  | Core logic for RAG, log processing, and LLM orchestration                |
| **LLM (Groq)**         | Detects anomalies and explains system issues                             |
| **Vector DB (Chroma)** | Embedding-based retrieval for contextually relevant log data             |
| **Firestore**          | Stores structured logs, anomalies, and user conversations                |

---

## ğŸ” End-to-End Flow

### 1ï¸âƒ£ Log Generation
**Endpoint:** `/fetch_and_store_logs`

- Generates realistic logs using **Groq LLM**.  
- Logs include mixed levels: `INFO`, `WARN`, `ERROR`, etc.

Example:
```
[2025-10-12T05:12:34Z] [ERROR] PaymentProcessor: NullPointerException while executing transaction ID 8392
```

---

### 2ï¸âƒ£ Log Parsing & Embedding
**Endpoint:** `/store_logs`

1. Groq LLM + **PydanticOutputParser** parses raw logs into structured format:
   ```json
   {
     "timestamp": "2025-10-12T05:12:34Z",
     "log_level": "ERROR",
     "service_name": "PaymentProcessor",
     "error_code": "NPE8392",
     "message": "NullPointerException while executing transaction ID 8392"
   }
   ```
2. The message is embedded using **HuggingFace Sentence Transformers** (`all-MiniLM-L6-v2`).
3. Stored in:
   - ğŸ§  **Chroma VectorDB** â€” embeddings for semantic search  
   - ğŸ”¥ **Firestore** â€” structured log storage

---

### 3ï¸âƒ£ Anomaly Detection
After storage:
- **Groq LLM** analyzes recent logs.
- Detects anomalies, probable causes, and recommends actions.

Example:
```json
{
  "summary": "High latency detected in AuthService",
  "detected_anomalies": ["Memory Leak", "Slow Response"],
  "probable_causes": ["Thread blocking in API handler"],
  "severity_level": "Critical",
  "recommended_action": "Restart AuthService and run profiling."
}
```

---

### 4ï¸âƒ£ Conversational AI â€” Retrieval-Augmented Generation (RAG)
**Endpoint:** `/ask_ai`

Query example:
> â€œWhy are there so many 500 errors in the BillingAPI logs?â€

Flow:
1. Retrieve relevant log embeddings from **Chroma**.
2. Fetch recent conversation context from **Firestore**.
3. Construct contextual prompt:
   ```
   Summary: Past issues with DB timeouts
   Logs: [...retrieved logs...]
   Question: Why did 500 errors spike?
   ```
4. Send to **Groq LLM**.
5. LLM responds:
   ```
   The spike in 500 errors was caused by database connection pool exhaustion between 3:20â€“3:45 AM.
   Increasing pool size should resolve the issue.
   ```

---

### 5ï¸âƒ£ Conversation Management

Conversations are stored like this:
```
user_conversations/
 â””â”€â”€ {username}/
      â””â”€â”€ tenants/{tenant_id}/apps/{app_id}/conversations/{convo_id}/messages/
           â”œâ”€â”€ user: "Why are there errors?"
           â”œâ”€â”€ assistant: "Database pool exhausted."
```

When message history grows, older logs are summarized automatically to maintain context â€” **context window optimization**.

---

## ğŸ§± Firestore Schema

| Path                                                  | Purpose                           |
| ----------------------------------------------------- | --------------------------------- |
| `/logs/{tenant_id}/{app_id}`                          | Structured log entries            |
| `/anomalies/{tenant_id}/{app_id}`                     | Detected anomalies                |
| `/user_conversations/{username}/{tenant_id}/{app_id}` | Chat history                      |
| `/chroma_store/`                                      | Local vector embeddings directory |

---

## ğŸ§© How RAG Works

```text
[User Query] â†’ [Retriever: Chroma] â†’ [Relevant Logs]
         â†“
   [Groq LLM: Reasoning + Contextual Understanding]
         â†“
[Contextual Answer Grounded in Actual Logs]
```

**Pipeline:**
1. Retrieve top-K relevant log embeddings from **Chroma**.
2. Combine with chat history and context.
3. Pass into **Groq model** for grounded reasoning.

This ensures **zero hallucination** and **true log-grounded responses**.

---

## ğŸ§° Tech Stack

| Layer            | Technologies                                                   |
| ---------------- | -------------------------------------------------------------- |
| **Frontend**     | React.js, Axios, Firestore (Realtime)                          |
| **Backend**      | FastAPI, LangChain, Groq LLM, Pydantic, HuggingFace Embeddings |
| **Database**     | Firestore                                                      |
| **Vector Store** | Chroma                                                         |
| **LLM**          | Groq `llama3-70b-8192`                                         |
| **Embeddings**   | Sentence Transformers (`all-MiniLM-L6-v2`)                     |
| **Language**     | Python 3.11, Node.js 18+                                       |

---

## ğŸ“Š Dashboard Features

1. **Recent Logs Table**
   - Displays structured logs for each tenant/app.

2. **Anomaly Trend Chart**
   - Visualizes anomaly frequency and severity over time.

3. **Conversational Chat Panel**
   - Real-time AI chat using Groq LLM for insights.

4. **Live Sync**
   - Uses Firestore `onSnapshot()` for instant message updates.

---

## ğŸ§­ Future Enhancements

- [ ] Automated log ingestion CRON (every 5 mins)
- [ ] WebSocket streaming for LLM responses
- [ ] Multi-tenant analytics dashboard
- [ ] Integration with Prometheus/Grafana metrics
- [ ] Enhanced RAG summarization + memory compression

---

## ğŸ§© API Endpoints Summary

| Method | Endpoint                 | Description                           |
| ------- | ------------------------ | ------------------------------------- |
| `POST` | `/fetch_and_store_logs`  | Generate and store synthetic logs     |
| `POST` | `/store_logs`            | Parse, embed, and detect anomalies    |
| `POST` | `/ask_ai`                | Conversational insights via Groq LLM  |
| `GET`  | `/analyze`               | Retrieve past anomaly reports         |

---

## ğŸ‘¨â€ğŸ’» Author

**Biswajeet Raut**  
*Full Stack & AI Engineer*  
ğŸš€ Building intelligent backend systems merging LLMs with observability.  
ğŸ“§ [biswajeetraut382@gmail.com](mailto:biswajeetraut382@gmail.com)

---

## ğŸ“œ License

Licensed under the **MIT License** â€” free to use, modify, and distribute.

---

## âœ… Quick Recap

Anamoli AI is your **self-learning observability assistant** â€” it:
- Understands logs ğŸ§©  
- Detects anomalies âš ï¸  
- Learns from incidents ğŸ“–  
- Chats about your system health ğŸ’¬  

**Built with ğŸ’™ using FastAPI, LangChain, Groq, Firestore & React.**
